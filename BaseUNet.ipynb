{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "oAEGBpMzrcnQ",
        "outputId": "224f52e2-dc74-48e9-cbfd-4ca31a0cf224"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8giolEEr7IU"
      },
      "outputs": [],
      "source": [
        "!pip install -q gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgYImjQ1skmT",
        "outputId": "0b86b5ae-7267-4d31-efbc-654b5b5afc06"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d debeshjha1/kvasirseg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQmrSAkDuBNY",
        "outputId": "f367aa36-7228-4089-a32b-dbc2e73eb4b5"
      },
      "outputs": [],
      "source": [
        "!unzip -q kvasirseg.zip -d kvasir_raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkDW2H-OuOKV"
      },
      "outputs": [],
      "source": [
        "!mkdir -p polyp_data/images polyp_data/masks\n",
        "!cp -r kvasir_raw/Kvasir-SEG//Kvasir-SEG/images/* polyp_data/images/\n",
        "!cp -r kvasir_raw/Kvasir-SEG//Kvasir-SEG/masks/* polyp_data/masks/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT0UGnVlvkz8",
        "outputId": "f90efc90-b8c6-4ab2-8e63-5d79116dfaf4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "print(\"Images:\", len(os.listdir(\"polyp_data/images\")))\n",
        "print(\"Masks:\", len(os.listdir(\"polyp_data/masks\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iie9427vvBx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import random\n",
        "from torchvision import transforms\n",
        "\n",
        "class FewShotPolypDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, support_shots=3, image_size=256):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.support_shots = support_shots\n",
        "        self.image_size = image_size\n",
        "\n",
        "        self.image_list = sorted(os.listdir(image_dir))  # ensure consistent ordering\n",
        "        self.mask_list = sorted(os.listdir(mask_dir))\n",
        "\n",
        "        assert len(self.image_list) == len(self.mask_list), \"Mismatch in image and mask count\"\n",
        "\n",
        "        self.transform_image = transforms.Compose([\n",
        "            transforms.Resize((image_size, image_size)),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "        self.transform_mask = transforms.Compose([\n",
        "            transforms.Resize((image_size, image_size)),\n",
        "            transforms.ToTensor(),  # returns (1, H, W)\n",
        "        ])\n",
        "\n",
        "        # Random 3-shot support set\n",
        "        self.support_indices = random.sample(range(len(self.image_list)), support_shots)\n",
        "        self.query_indices = [i for i in range(len(self.image_list)) if i not in self.support_indices]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.query_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Query sample\n",
        "        query_idx = self.query_indices[idx]\n",
        "        query_image = Image.open(os.path.join(self.image_dir, self.image_list[query_idx])).convert('RGB')\n",
        "        query_mask = Image.open(os.path.join(self.mask_dir, self.mask_list[query_idx])).convert('L')\n",
        "\n",
        "        query_image = self.transform_image(query_image)\n",
        "        query_mask = self.transform_mask(query_mask)\n",
        "        query_mask = (query_mask > 0.5).float()  # binarize\n",
        "\n",
        "        # Support set\n",
        "        support_images = []\n",
        "        support_masks = []\n",
        "        for s_idx in self.support_indices:\n",
        "            s_image = Image.open(os.path.join(self.image_dir, self.image_list[s_idx])).convert('RGB')\n",
        "            s_mask = Image.open(os.path.join(self.mask_dir, self.mask_list[s_idx])).convert('L')\n",
        "\n",
        "            s_image = self.transform_image(s_image)\n",
        "            s_mask = self.transform_mask(s_mask)\n",
        "            s_mask = (s_mask > 0.5).float()\n",
        "\n",
        "            support_images.append(s_image)\n",
        "            support_masks.append(s_mask)\n",
        "\n",
        "        support_images = torch.stack(support_images)  # (K, 3, H, W)\n",
        "        support_masks = torch.stack(support_masks)    # (K, 1, H, W)\n",
        "\n",
        "        return {\n",
        "            'query_image': query_image,\n",
        "            'query_mask': query_mask,\n",
        "            'support_images': support_images,\n",
        "            'support_masks': support_masks\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8PcNBgRv3jR",
        "outputId": "0789d16a-4b36-4de9-bf17-27e269100aa8"
      },
      "outputs": [],
      "source": [
        "dataset = FewShotPolypDataset(\"polyp_data/images\", \"polyp_data/masks\", support_shots=3)\n",
        "sample = dataset[0]\n",
        "\n",
        "print(\"Query image:\", sample['query_image'].shape)\n",
        "print(\"Query mask :\", sample['query_mask'].shape)\n",
        "print(\"Support images:\", sample['support_images'].shape)\n",
        "print(\"Support masks :\", sample['support_masks'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sO0PR7-HwAJH"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class UNetProto(nn.Module):\n",
        "    def __init__(self, in_ch=3, base_ch=32):\n",
        "        super().__init__()\n",
        "        # Encoder\n",
        "        self.enc1 = ConvBlock(in_ch, base_ch)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = ConvBlock(base_ch, base_ch * 2)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.enc3 = ConvBlock(base_ch * 2, base_ch * 4)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = ConvBlock(base_ch * 4, base_ch * 8)\n",
        "\n",
        "        # Decoder (NO skip connections)\n",
        "        self.up2 = nn.ConvTranspose2d(base_ch * 8, base_ch * 4, 2, stride=2)\n",
        "        self.dec2 = ConvBlock(base_ch * 4, base_ch * 4)\n",
        "        self.up1 = nn.ConvTranspose2d(base_ch * 4, base_ch * 2, 2, stride=2)\n",
        "        self.dec1 = ConvBlock(base_ch * 2, base_ch * 2)\n",
        "        self.final_up = nn.ConvTranspose2d(base_ch * 2, base_ch, 2, stride=2)\n",
        "        self.final = nn.Conv2d(base_ch, 1, 1)\n",
        "\n",
        "    def forward_encoder(self, x):\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool1(e1))\n",
        "        e3 = self.enc3(self.pool2(e2))\n",
        "        b = self.bottleneck(self.pool3(e3))\n",
        "        return b\n",
        "\n",
        "    def forward_decoder(self, x):\n",
        "        x = self.up2(x)\n",
        "        x = self.dec2(x)\n",
        "        x = self.up1(x)\n",
        "        x = self.dec1(x)\n",
        "        x = self.final_up(x)\n",
        "        out = self.final(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11TrbKSbwCWD"
      },
      "outputs": [],
      "source": [
        "def compute_prototype(support_feats, support_masks):\n",
        "    # support_feats: (K, C, H, W)\n",
        "    # support_masks: (K, 1, H, W)\n",
        "    K, C, H, W = support_feats.shape\n",
        "    support_masks = F.interpolate(support_masks, size=(H, W), mode='nearest')\n",
        "\n",
        "    masked_feats = support_feats * support_masks  # apply mask\n",
        "    proto = masked_feats.sum(dim=(0, 2, 3)) / (support_masks.sum(dim=(0, 2, 3)) + 1e-5)\n",
        "    return proto  # (C,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXYpnI_nwKDY"
      },
      "outputs": [],
      "source": [
        "class FewShotSegModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.unet = UNetProto()\n",
        "\n",
        "    def forward(self, query_img, support_imgs, support_masks):\n",
        "        # Support encoding\n",
        "        support_feats = self.unet.forward_encoder(support_imgs)  # (K, C, H, W)\n",
        "        proto = compute_prototype(support_feats, support_masks)  # (C,)\n",
        "\n",
        "        # Query encoding\n",
        "        query_feat = self.unet.forward_encoder(query_img.unsqueeze(0))  # (1, C, H, W)\n",
        "\n",
        "        # Expand proto and fuse via cosine similarity\n",
        "        proto = proto.view(1, -1, 1, 1)  # (1, C, 1, 1)\n",
        "        sim_map = F.cosine_similarity(query_feat, proto, dim=1).unsqueeze(1)  # (1, 1, H, W)\n",
        "        fused_feat = query_feat * sim_map  # element-wise weighting\n",
        "\n",
        "        # Decode the fused feature map\n",
        "        out = self.unet.forward_decoder(fused_feat)\n",
        "        return torch.sigmoid(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYqZFRqbxRjK",
        "outputId": "71fd8b5d-19b7-4b46-b9c1-ef1e43ce14b7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5g01bvJwLX7"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def dice_loss(pred, target, smooth=1.):\n",
        "    pred = pred.contiguous()\n",
        "    target = target.contiguous()\n",
        "\n",
        "    intersection = (pred * target).sum(dim=(2, 3))\n",
        "    dice = (2. * intersection + smooth) / (pred.sum(dim=(2, 3)) + target.sum(dim=(2, 3)) + smooth)\n",
        "    return 1 - dice.mean()\n",
        "\n",
        "def combined_loss(pred, target):\n",
        "    bce = F.binary_cross_entropy(pred, target)\n",
        "    dice = dice_loss(pred, target)\n",
        "    return bce + dice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4Nl-KJMwqkc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_sample(query_img, pred_mask, gt_mask):\n",
        "    pred_mask = (pred_mask.squeeze().cpu().detach().numpy() > 0.5).astype(float)\n",
        "    gt_mask = gt_mask.squeeze().cpu().numpy()\n",
        "    query_img = query_img.permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    axs[0].imshow(query_img)\n",
        "    axs[0].set_title(\"Query Image\")\n",
        "    axs[1].imshow(gt_mask, cmap='gray')\n",
        "    axs[1].set_title(\"Ground Truth\")\n",
        "    axs[2].imshow(pred_mask, cmap='gray')\n",
        "    axs[2].set_title(\"Prediction\")\n",
        "    for ax in axs:\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N5x9BHqwtGI",
        "outputId": "63c27d1f-8aa9-4c3d-f899-27132ba0570c"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "# Reload your dataset with 3-shot\n",
        "dataset = FewShotPolypDataset(\"polyp_data/images\", \"polyp_data/masks\", support_shots=3)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Model and optimizer\n",
        "model = FewShotSegModel().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Training\n",
        "for epoch in range(5):  # increase to 20+ for real training\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        query_img = batch['query_image'].to(device)\n",
        "        query_mask = batch['query_mask'].to(device)\n",
        "        support_imgs = batch['support_images'].to(device)\n",
        "        support_masks = batch['support_masks'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(\n",
        "            query_img.squeeze(0),\n",
        "            support_imgs.squeeze(0),\n",
        "            support_masks.squeeze(0)\n",
        "        )\n",
        "        loss = combined_loss(pred, query_mask)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(dataloader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "a1W3uR73nKXA",
        "outputId": "eaa4e05d-c5d0-4e5d-dc04-3eab40de5999"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    sample = dataset[0]\n",
        "    q_img = sample['query_image'].to(device)\n",
        "    q_mask = sample['query_mask'].to(device)\n",
        "    s_imgs = sample['support_images'].to(device)\n",
        "    s_masks = sample['support_masks'].to(device)\n",
        "\n",
        "    pred_mask = model(q_img, s_imgs, s_masks)\n",
        "    visualize_sample(q_img.cpu(), pred_mask.cpu(), q_mask.cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afRGYmGJncrr"
      },
      "outputs": [],
      "source": [
        "def compute_all_metrics(pred_mask, true_mask, threshold=0.5):\n",
        "    pred_bin = (pred_mask > threshold).float()\n",
        "    true_bin = (true_mask > 0.5).float()\n",
        "\n",
        "    TP = (pred_bin * true_bin).sum()\n",
        "    FP = (pred_bin * (1 - true_bin)).sum()\n",
        "    FN = ((1 - pred_bin) * true_bin).sum()\n",
        "    TN = ((1 - pred_bin) * (1 - true_bin)).sum()\n",
        "\n",
        "    epsilon = 1e-8\n",
        "    dice = (2 * TP) / (2 * TP + FP + FN + epsilon)\n",
        "    iou = TP / (TP + FP + FN + epsilon)\n",
        "    precision = TP / (TP + FP + epsilon)\n",
        "    recall = TP / (TP + FN + epsilon)\n",
        "    f1 = (2 * precision * recall) / (precision + recall + epsilon)\n",
        "    accuracy = (TP + TN) / (TP + FP + FN + TN + epsilon)\n",
        "\n",
        "    return {\n",
        "        'Dice': dice.item(),\n",
        "        'IoU': iou.item(),\n",
        "        'Precision': precision.item(),\n",
        "        'Recall': recall.item(),\n",
        "        'F1 Score': f1.item(),\n",
        "        'Accuracy': accuracy.item()\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USmbHyw9neSn",
        "outputId": "d58a1aef-f895-4f2b-bce2-72ed670baa3f"
      },
      "outputs": [],
      "source": [
        "metrics = compute_all_metrics(pred_mask.cpu(), q_mask.cpu())\n",
        "for k, v in metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
